defaults:
  - override hydra/job_logging: default
  - override hydra/hydra_logging: default

hydra:
  run:
    dir: ./outputs/${now:%m-%d}/${now:%H-%M-%S}


## WANDB params
# The wandb project name
name: testing_logging_changes
project: lux-ai-s1
# The wandb user to log to
entity: rwill128
# The wandb group for the run
group: first_run

## ENV params
act_space: BasicActionSpace
obs_space: FixedShapeContinuousObsV2
obs_space_kwargs: {}
reward_space: StatefulMultiReward
reward_space_kwargs:
  #early_stop: True
  #city: 2.
  #unit: 1.
  #fuel: 0.
  step: 0.005

## TRAINING params
total_steps: 2e7
num_actors: 2
n_actor_envs: 16
unroll_length: 16
batch_size: 4
discounting: 0.999

## MODEL params
model_arch: conv_model
n_blocks: 8
hidden_dim: 128
embedding_dim: 32
n_merge_layers: 1
normalize: False
sum_player_embeddings: False
use_index_select: False
rescale_value_input: True
rescale_se_input: True
# Conv-specific params
kernel_size: 5

use_mixed_precision: true

## OPTIMIZER params
optimizer_class: Adam
optimizer_kwargs:
  lr: 1e-6
  # See https://arxiv.org/pdf/2105.05246.pdf
  eps: 0.0003
  #alpha: 0.9
min_lr_mod: 0.01

## LOSS params
entropy_cost: 0.0002
baseline_cost: 1.
teacher_kl_cost: 0.01
# lambda parameter for TD-lambda and UPGO losses
lmb: 0.8
reduction: sum

# MISCELLANEOUS params
actor_device: cuda:0
learner_device: cuda:0
disable_wandb: False
model_log_freq: 100
# file_descriptor or file_system
sharing_strategy: file_descriptor

# Pretrained model for KL loss
#use_teacher: True
#teacher_load_dir: /home/rick/IdeaProjects/Kaggle_Lux_AI_2021/teacher # E.g. .../outputs/09-01/09-58-50/
#teacher_checkpoint_file: 03764544.pt # E.g. 05079552.pt

#load_dir: /home/rick/IdeaProjects/Kaggle_Lux_AI_2021/
#checkpoint_file: 00434368_weights.pt
#weights_only: True